{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS429 - Lab 6: Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "import operator\n",
    "import math\n",
    "\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"Lab 6\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://cluster:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Lab 6</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=Lab 6>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding indices of attributes for each training example\n",
    "attribute_indx = {\n",
    "    'Outlook': 0,\n",
    "    'Temperature': 1,\n",
    "    'Humidity': 2,\n",
    "    'Wind': 3,\n",
    "    'class': 4\n",
    "}\n",
    "\n",
    "# Domain values of attributes\n",
    "attribute_values = {\n",
    "    'Outlook': ['Sunny', 'Overcast', 'Rain'],\n",
    "    'Temperature': ['Hot', 'Mild', 'Cool'],\n",
    "    'Humidity': ['High', 'Normal'],\n",
    "    'Wind': ['Weak', 'Strong']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_counts(examples):\n",
    "    \"\"\"Count the number of examples per class.\n",
    "        @params\n",
    "            examples (PythonRDD): training examples\n",
    "        @return\n",
    "            class_cnts (list(dict())): examples count per class\n",
    "    \"\"\"\n",
    "    count_by_class = examples.map(lambda x: (x[attribute_indx['class']], 1)).reduceByKey(lambda x,y: x+y).collect()\n",
    "    count_all = examples.count()\n",
    "    class_cnts = [(k, v/count_all) for k,v in count_by_class]\n",
    "    return class_cnts\n",
    "   \n",
    "class Leaf:\n",
    "    \"\"\"A leaf node in decision tree. Leaf nodes contain the final prediction.\n",
    "        @attributes\n",
    "            self.node_name (str): uniqe name for each node\n",
    "            self.label (str): label for printing\n",
    "            self.leading_branch (str): value of parent node that leads to this node            \n",
    "    \"\"\"\n",
    "    nodeid = 0\n",
    "    def __init__(self, examples, leading_branch):\n",
    "        if examples.count()==0:\n",
    "            self.node_name = 'leaf' + str(Leaf.nodeid)\n",
    "            Leaf.nodeid += 1\n",
    "            self.label = 'N/A'\n",
    "            self.leading_branch = leading_branch\n",
    "        else:\n",
    "            self.predictions = class_counts(examples)\n",
    "            self.node_name = 'leaf' + str(Leaf.nodeid)\n",
    "            Leaf.nodeid += 1\n",
    "            self.label = ', '.join(['{0:.0f}% {1}'.format(p*100, c) for c,p in self.predictions]) # assign the class prediction to self.node_name\n",
    "            self.leading_branch = leading_branch\n",
    "    def isLeaf(self):\n",
    "        return True\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.label\n",
    "    \n",
    "\n",
    "class DecisionNode:\n",
    "    \"\"\"A decision node in decision tree.\n",
    "        @attributes\n",
    "            self.node_name (str) : uniqe name for each node\n",
    "            self.label (str): label for printing\n",
    "            self.leading_branch (str): value of parent node that leads to this node\n",
    "            self.children (dict()): children nodes, each is a dict entry of {'attribute_value':node}, where node is either DecisionNode or Leaf\n",
    "    \"\"\"\n",
    "    nodeid = 0\n",
    "    def __init__(self, label, leading_branch, children=dict()):\n",
    "        self.node_name = 'node' + str(DecisionNode.nodeid)\n",
    "        DecisionNode.nodeid += 1\n",
    "        self.label = label\n",
    "        self.leading_branch = leading_branch\n",
    "        self.children = children\n",
    "        \n",
    "    def isLeaf(self):\n",
    "        return False\n",
    "    \n",
    "    def predict(self, x):\n",
    "        split_attr_value = x[attribute_indx[self.label]]\n",
    "        return self.children[split_attr_value].predict(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBestGainAttr(examples, attributes):\n",
    "    \"\"\"Find the best attribute to split using Information Gain.\n",
    "        @params\n",
    "            examples (PythonRDD): training examples\n",
    "            attributes: (dict()): a dict of remaining attributes and their values, where each entry is (attribute_name, list(attribute_values))\n",
    "        @return:\n",
    "            best_attribute (str): name of best attribute to split\n",
    "    \"\"\"\n",
    "    #TODO: implement this function\n",
    "    \n",
    "    return best_attribute\n",
    "    \n",
    "def build_tree(examples, leading_branch, attributes):\n",
    "    \"\"\"Recursively build decision tree, one node at a time.\n",
    "        @params\n",
    "            examples (PythonRDD): training examples\n",
    "            leading_branch (str): value of parent node that leads to this node\n",
    "            attributes: (dict()): a dict of remaining attributes and their values, where each entry is (attribute_name, list(attribute_values))\n",
    "        @return\n",
    "            a tree root (DecisionNode)\n",
    "    \"\"\"\n",
    "    #TODO: implement this function\n",
    "    \n",
    "    # base cases\n",
    "    \n",
    "    # select best attribute for splitting\n",
    "    best_attribute = findBestGainAttr(examples, attributes)\n",
    "    \n",
    "    # build tree recursively\n",
    "    children = dict()\n",
    "    \n",
    "    return DecisionNode(best_attribute, leading_branch, children)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build decision tree\n",
    "tree = build_tree(data, '', attribute_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Visualization\n",
    "To visualize decision tree using `graphviz` you need to install `xdg-utils` package on your virtual machine\n",
    "```bash\n",
    "sudo apt-get install --reinstall xdg-utils\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree_graph(root_node, tree_):\n",
    "    \"\"\"Print decision tree.\n",
    "        @params\n",
    "            root_node (DecisionNode): tree root node\n",
    "            tree_ (graphviz.Digraph): the graph to print\n",
    "    \"\"\"\n",
    "    if not root_node.isLeaf():\n",
    "        tree_.node(root_node.node_name, label=root_node.label, shape='diamond')\n",
    "        for c in root_node.children.values():\n",
    "            tree_.edge(root_node.node_name, c.node_name, label=c.leading_branch)\n",
    "            print_tree(c, tree_)\n",
    "    if root_node.isLeaf():\n",
    "        tree_.node(root_node.node_name, label=root_node.label, shape='oval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print decision tree\n",
    "tree_view = Digraph()\n",
    "build_tree_graph(tree,tree_view)\n",
    "tree_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'67% Yes, 33% No'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting\n",
    "x = ['Sunny', 'Cool', 'Normal', 'Weak']\n",
    "tree.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
